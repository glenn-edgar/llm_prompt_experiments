Many prompt sections are reused across multiple prompts. Restructuring these prompts in a token-efficient manner is crucial for lowering large language model (LLM) costs. This study aimed to evaluate whether LLMs could effectively restructure prompt text to minimize token usage.

No AI understood the concept



